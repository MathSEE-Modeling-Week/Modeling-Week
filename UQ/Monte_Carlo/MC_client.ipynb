{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbf1e4b",
   "metadata": {},
   "source": [
    "## 1.3 UM-Bridge Client\n",
    "\n",
    "In this section, we will implement the client-side code to interact with the UM-Bridge model server, which was defined previously [here](https://github.com/MathSEE-Modeling-Week/Modeling-Week/blob/main/UQ/Monte_Carlo/MC_server.ipynb). This will allow us to perform a Monte Carlo simulation to estimate the integral of the function $f(x) = \\sin(2\\pi x)$.\n",
    "\n",
    "### MC Client Template\n",
    "\n",
    "Below is a general template for implementing the Monte Carlo (MC) method as an UM-Bridge client. Remember that the MC estimator is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{F}^{MC} = \\frac{1}{N} \\sum_{i=1}^{N} f(x_i),\n",
    "\\end{equation}\n",
    "\n",
    "where $x_i, i =1,...,N$ are realizations of the random variables $X_i$ and $f(x_i)$ represent the model evaluation for each sample $X_i, i=1,...,N$.\n",
    "\n",
    "\n",
    "```python\n",
    "# Monte Carlo Client Template for General MC Estimator\n",
    "\n",
    "import numpy as np\n",
    "import umbridge\n",
    "\n",
    "# Connect to the model server\n",
    "# Replace with your actual model URL and model name\n",
    "model = umbridge.HTTPModel(\"http://<server-address>:<port>\", \"<model-name>\")\n",
    "\n",
    "# Define the number of samples for the Monte Carlo simulation\n",
    "N = <number_of_samples>\n",
    "\n",
    "# Sample X_i from a distribution\n",
    "# Replace <distribution> with the distribution you consider for MC\n",
    "X_i_samples = [<distribution>(<param_1>, <param_2>, <param_size>).tolist() for _ in range(N)]\n",
    "# Example: X_i_samples = [np.random.uniform(0, 1, 1).tolist() for _ in range(N)]\n",
    "\n",
    "# Monte Carlo simulation: Evaluate the model for each sample X_i -> f(X_i)\n",
    "mc_values = [model([X_i])[0][0] for X_i in X_i_samples]  # Modify as needed\n",
    "\n",
    "# Compute the Monte Carlo estimator: \\hat{F}^{MC} = (1/N) * sum(f(X_i))\n",
    "mc_estimator = np.mean(mc_values)\n",
    "print(\"Monte Carlo Estimator (mean of evaluations):\", mc_estimator)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### MC Client for Solving an Integral\n",
    "\n",
    "Next, we will implement the MC client to compute the value of the integral:\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{0}^{1} f(x) \\textit{d}x.\n",
    "\\end{equation}\n",
    "\n",
    "From basic analysis, we know that for $f(x) = \\sin(2\\pi x)$ the exact value of this integral is $0$. To estimate this integral using MC simulation, we sample $N$ uniformly distributed random variables $X_i \\sim \\mathscr{U}([0,1])$, $i=1,...,N$. \n",
    "\n",
    "Since\n",
    "\n",
    "$\\mathbb{E}[f(X_i)] = \\int_{0}^{1} f(x) \\textit{d}x$,\n",
    "\n",
    "the choice of the distribution for $X_i$ provides an unbiased estimator for the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7614c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten parameters: [[0.8706080117991248], [0.13244494965600662], [0.5076992710333947], [0.2428955294556927], [0.1120323797472873], [0.38042373882307357], [0.3434180589147875], [0.956555804923446], [0.4806179552064962], [0.8981198774492936]] \n",
      "\n",
      "First ten model evaluations: [-0.7263481727585729, 0.7393982614219202, -0.04835708034929064, 0.99900385843762, 0.6472110655448976, 0.6826038543936931, 0.8326265266319042, -0.26959066053474917, 0.12148018789807949, -0.5973010634556816] \n",
      "\n",
      "MC estimator: -0.0531669564566899 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# umbridge client\n",
    "import numpy as np\n",
    "import umbridge\n",
    "\n",
    "model = umbridge.HTTPModel(\"http://localhost:4242\", \"forward\")\n",
    "\n",
    "N = 100 # Number of samples\n",
    "\n",
    "# Monte Carlo simulation\n",
    "\n",
    "# Generate N random samples from a uniform distribution over [0, 1] and convert each to a list\n",
    "parameters = [np.random.rand(1).tolist() for _ in range(N)]\n",
    "print(\"First ten parameters:\", parameters[:10], \"\\n\") # print first 10 parameters\n",
    "\n",
    "mc_values = [model([parameters])[0][0] for parameters in parameters]  # model evaluation for each parameter\n",
    "print(\"First ten model evaluations:\", mc_values[:10], \"\\n\")\n",
    "\n",
    "mc_mean = np.mean(mc_values)  # calculate mean\n",
    "print(\"MC estimator:\", mc_mean, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff247450",
   "metadata": {},
   "source": [
    "### Understanding the Results\n",
    "\n",
    "- **Monte Carlo Estimator**: The estimator uses random samples from the uniform distribution $[0, 1]$ and evaluates the UM-Bridge model $f(x) = \\sin(2\\pi x)$ for each sample. The estimator is the mean of these evaluations.\n",
    "- **Sample Size \\( N \\)**: The accuracy of the Monte Carlo method depends on the number of samples $N$. Increasing $N$ generally improves the estimate's accuracy, though the method converges slowly with an error proportional to $\\mathcal{O}(N^{-1/2})$.\n",
    "\n",
    "---\n",
    "\n",
    "### Tasks\n",
    "\n",
    "You can experiment with the MC method by adjusting the following:\n",
    "\n",
    "1. **Change the Sample Size**: Try increasing $N$ to improve the accuracy of the estimator and observe how the result changes.\n",
    "2. **Change the Function**: To estimate the integral of another function, modify the `Testmodel` class in the model server. Change the definition of `posterior` to evaluate a different 1D function of your interest.\n",
    "\n",
    "#### Remarks\n",
    "\n",
    "- The **convergence** of the basic Monte Carlo method is dimension-independent, meaning it works in any dimension. However, the convergence rate is relatively slow at $\\mathcal{O}(N^{-1/2})$, making it inefficient for high-dimensional problems.\n",
    "- **Quasi-Monte Carlo (QMC)** methods can improve convergence to $\\mathcal{O}(N^{-1})$, but they typically require smoothness in the function being integrated. QMC methods are also dimension-independent, though they perform better in low to moderate dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370a15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
